# llm_tools.py

from typing import List
from langchain_core.documents import Document
from prompt_builder import build_user_story_prompt


def extract_relevant_info(llm, query: str, docs: List[Document]) -> str:
    """
    Uses an LLM to extract only the relevant information from a set of documents.

    Parameters:
    - llm: an instance of ChatOpenAI or other model supporting `.invoke()`.
    - query: user query string
    - docs: list of retrieved Document objects

    Returns:
    - Text string with relevant information filtered by the LLM.
    """
    context_text = "\n\n".join([doc.page_content for doc in docs])

    extractor_prompt = f"""You are a smart assistant helping a product manager.
From the following documentation, extract only the information that is strictly relevant to the query.

Query:
"{query}"

Documentation:
{context_text}

Return only the relevant content, no explanations, no formatting.
"""

    response = llm.invoke(extractor_prompt)
    return response.content.strip()


def generate_full_context_story(llm_full, query: str, all_docs: List[Document]) -> str:
    """
    Generates a user story using the FULL context (all documents concatenated).
    Uses a more powerful LLM model (e.g., gpt-4o) that supports larger token context.

    Parameters:
    - llm_full: an instance of ChatOpenAI with a higher capacity model
    - query: user query string
    - all_docs: list of all Document objects

    Returns:
    - Text generated by the LLM with the full context user story.
    """
    full_context_text = "\n\n".join([doc.page_content for doc in all_docs])

    prompt = build_user_story_prompt(query, full_context_text)

    response = llm_full.invoke(prompt)
    return response.content.strip()
